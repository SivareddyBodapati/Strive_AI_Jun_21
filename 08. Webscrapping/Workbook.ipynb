{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API REQUEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "{\n",
      "    \"message\": \"success\",\n",
      "    \"request\": {\n",
      "        \"altitude\": 100,\n",
      "        \"datetime\": 1622584397,\n",
      "        \"latitude\": 40.71,\n",
      "        \"longitude\": -74.0,\n",
      "        \"passes\": 5\n",
      "    },\n",
      "    \"response\": [\n",
      "        {\n",
      "            \"duration\": 565,\n",
      "            \"risetime\": 1622586645\n",
      "        },\n",
      "        {\n",
      "            \"duration\": 632,\n",
      "            \"risetime\": 1622592469\n",
      "        },\n",
      "        {\n",
      "            \"duration\": 637,\n",
      "            \"risetime\": 1622598278\n",
      "        },\n",
      "        {\n",
      "            \"duration\": 290,\n",
      "            \"risetime\": 1622604211\n",
      "        },\n",
      "        {\n",
      "            \"duration\": 495,\n",
      "            \"risetime\": 1622652747\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup   \n",
    "\n",
    "# Set up the parameters we want to pass to the API.\n",
    "# This is the latitude and longitude of New York City.\n",
    "parameters = {\"lat\": 40.71, \"lon\": -74}\n",
    "# Make a get request with the pahttp://api.open-notify.orgrameters.\n",
    "response = requests.get(\"http://api.open-notify.org/iss-pass.json\", params=parameters)\n",
    "\n",
    "#is the response positive?\n",
    "print(response)\n",
    "\n",
    "# Print the content of the response (the data the server returned)\n",
    "#print(response.content)\n",
    "\n",
    "# save response into a much nicer format\n",
    "a = response.json()\n",
    "#print(response.json())\n",
    "\n",
    "pretty_json = json.dumps(a, indent=4, sort_keys=True)\n",
    "print(pretty_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"message\": \"success\",\n",
      "    \"request\": {\n",
      "        \"altitude\": 100,\n",
      "        \"datetime\": 1622584397,\n",
      "        \"latitude\": 37.78,\n",
      "        \"longitude\": -122.41,\n",
      "        \"passes\": 5\n",
      "    },\n",
      "    \"response\": [\n",
      "        {\n",
      "            \"duration\": 642,\n",
      "            \"risetime\": 1622586003\n",
      "        },\n",
      "        {\n",
      "            \"duration\": 537,\n",
      "            \"risetime\": 1622591908\n",
      "        },\n",
      "        {\n",
      "            \"duration\": 493,\n",
      "            \"risetime\": 1622597819\n",
      "        },\n",
      "        {\n",
      "            \"duration\": 597,\n",
      "            \"risetime\": 1622603643\n",
      "        },\n",
      "        {\n",
      "            \"duration\": 651,\n",
      "            \"risetime\": 1622609441\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Make the same request we did earlier, but with the coordinates of San Francisco instead.\n",
    "parameters = {\"lat\": 37.78, \"lon\": -122.41}\n",
    "response = requests.get(\"http://api.open-notify.org/iss-pass.json\", params=parameters)\n",
    "# Get the response data as a python object. Verify that it's a dictionary.\n",
    "data = response.json()\n",
    "#print(type(data))\n",
    "#print(data)\n",
    "\n",
    "\n",
    "\n",
    "pretty_json = json.dumps(data, indent=4, sort_keys=True)\n",
    "print(pretty_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 594\n",
      "RiseTime: 1607524821\n",
      "\n",
      "Duration: 648\n",
      "RiseTime: 1607530588\n",
      "\n",
      "Duration: 581\n",
      "RiseTime: 1607536467\n",
      "\n",
      "Duration: 569\n",
      "RiseTime: 1607542344\n",
      "\n",
      "Duration: 638\n",
      "RiseTime: 1607548163\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"latlong_ny.json\", \"w\") as fp:\n",
    "    json.dump(a,fp) \n",
    "\n",
    "with open('latlong.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    for p in data['response']:\n",
    "        print(f\"Duration: {p['duration']}\")\n",
    "        print(f\"RiseTime: {p['risetime']}\")\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names are Name, Appearance, Origin\n",
      "\t The beer Edelweiss is White, and it is from Austria.\n",
      "\t The beer CuvÃ©e des Trolls is Blond, and it is from Belgium.\n",
      "\t The beer Choulette AmbrÃ©e is Amber, and it is from France.\n",
      "\t The beer Gulden Draak is Dark, and it is from Belgium.\n",
      "\t The beer Water is Crystal Clear, and it is from Anywhere.\n",
      "Processed 6 lines.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('./data/beers.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            print(f'Column names are {\", \".join(row)}')\n",
    "            line_count += 1\n",
    "        else:\n",
    "            print(f'\\t The beer {row[0]} is {row[1]}, and it is from {row[2]}.')\n",
    "            line_count += 1\n",
    "    print(f'Processed {line_count} lines.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV into Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names are Name, Appearance, Origin\n",
      "\tThe beer Edelweiss is White, and it is from Austria.\n",
      "\tThe beer CuvÃ©e des Trolls is Blond, and it is from Belgium.\n",
      "\tThe beer Choulette AmbrÃ©e is Amber, and it is from France.\n",
      "\tThe beer Gulden Draak is Dark, and it is from Belgium.\n",
      "\tThe beer Water is Crystal Clear, and it is from Anywhere.\n",
      "Processed 6 lines.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('./data/beers.csv', mode='r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            print(f'Column names are {\", \".join(row)}')\n",
    "            line_count += 1\n",
    "        print(f'\\tThe beer {row[\"Name\"]} is {row[\"Appearance\"]}, and it is from {row[\"Origin\"]}.')\n",
    "        line_count += 1\n",
    "    print(f'Processed {line_count} lines.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Power of Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Name     Appearance    Origin\n",
      "0         Edelweiss          White   Austria\n",
      "1  Cuvée des Trolls          Blond   Belgium\n",
      "2  Choulette Ambrée          Amber    France\n",
      "3      Gulden Draak           Dark   Belgium\n",
      "4             Water  Crystal Clear  Anywhere\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "df = pandas.read_csv('./data/beers.csv')\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# downloading html with requests library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "page = requests.get(\"http://dataquestio.github.io/web-scraping-pages/simple.html\")\n",
    "page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can print out the HTML content of the page using the content property: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!DOCTYPE html>\\n<html>\\n    <head>\\n        <title>A simple example page</title>\\n    </head>\\n    <body>\\n        <p>Here is some simple content for this page.</p>\\n    </body>\\n</html>'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "page = requests.get(\"http://dataquestio.github.io/web-scraping-pages/simple.html\")\n",
    "page\n",
    "\n",
    "page.status_code\n",
    "page.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Weather.gov\n",
    "    \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "page = requests.get(\"https://forecast.weather.gov/MapClick.php?lat=37.777120000000025&lon=-122.41963999999996\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "#html = list(soup.children)[2]\n",
    "#body = list(html.children)[3]\n",
    "\n",
    "sevendaylist = soup.find('ul', id='seven-day-forecast-list')\n",
    "allrows = sevendaylist.find_all('div')\n",
    "listoflabels = []\n",
    "for r in range (len(allrows)):\n",
    "    labels = allrows[r].find_all('div', class_=\"col-sm-2 forecast-label\")\n",
    "    for label in labels:\n",
    "        listoflabels.append(label.text)\n",
    "#print(listoflabels)\n",
    "weatherdesc = []\n",
    "for r in range(30):\n",
    "    description = allrows[r].find_all('div', class_=\"col-sm-10 forecast-text\")\n",
    "    for desc in description:\n",
    "        weatherdesc.append(desc.text)\n",
    "        print(desc.text)\n",
    "        \n",
    "dict[\"dayofweek\"] = listoflabels\n",
    "dict[\"description\"] = weatherdesc\n",
    "\n",
    "prin\n",
    "#print(body)\n",
    "\n",
    "#target parents\n",
    "#go deeper into childen\n",
    "#find p element or relevant class\n",
    "\n",
    "    #target day\n",
    "    #target temperature\n",
    "    #target summary \n",
    "    \n",
    "#save into a list\n",
    "#save into a dictionary?\n",
    "\n",
    "#{\"day1\":[\"sunday\", \"54\", 'today was a great sunny day '], \"day2\":[\"monday\", \"54\", 'today was a great sunny day ']}\n",
    "\n",
    "#load dict into pandas\n",
    "# create column names if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This are the children\n",
      "\n",
      "Here is some simple content for this page.\n"
     ]
    }
   ],
   "source": [
    "# For further information\n",
    "# https://www.dataquest.io/blog/python-api-tutorial/\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "page = requests.get(\"http://dataquestio.github.io/web-scraping-pages/simple.html\")\n",
    "# Print the status code of the response.\n",
    "\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "#print(soup.prettify())\n",
    "\n",
    "print()\n",
    "print(\"This are the children\")\n",
    "print()\n",
    "\n",
    "html = list(soup.children)[2]\n",
    "#print(html)\n",
    "\n",
    "body = list(html.children)[3]\n",
    "#print(body)\n",
    "\n",
    "p = list(body.children)[1]\n",
    "#print(p)\n",
    "\n",
    "#print(p.get_text())\n",
    "\n",
    "#Faster Way\n",
    "\n",
    "p = soup.find('p')\n",
    "\n",
    "print(p.get_text())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ['html', '\\n', \"<html> <head> <title>A simple example page</title></head><body><p>Here is some simple content for this page.</p></body></html>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<html> <head> <title>A simple example page</title></head><body><p>Here is some simple content for this page.</p></body></html>'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FindAll with BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"outer-text first-item\" id=\"second\">\n",
      "<b>\n",
      "                First outer paragraph.\n",
      "            </b>\n",
      "</p>\n"
     ]
    }
   ],
   "source": [
    "# https://www.dataquest.io/blog/python-api-tutorial/\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "page =requests.get(\"http://dataquestio.github.io/web-scraping-pages/ids_and_classes.html\")\n",
    "# Print the status code of the response.\n",
    "\n",
    "soup =BeautifulSoup(page.content, 'html.parser')\n",
    "#print(soup.prettify())\n",
    "\n",
    "outer = soup.find_all('p', class_='outer-text')[0]\n",
    "#outer = soup.find(id='first').string\n",
    "print(outer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<b>\n",
       "                First outer paragraph.\n",
       "            </b>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outer.find_all('b')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
